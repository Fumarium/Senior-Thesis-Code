# -*- coding: utf-8 -*-
"""FTP_rebuild.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UHr8ciXo5GmaapnxHbIWcz0D6ksBXMf4
"""

"""
The first step here is to parse files in PHHS format and covert them to CSV
in order to be more data science friendly
"""
from ast import literal_eval
import csv
import re

# helper functions

def parse_value(raw_str):
  """
  This attemps to parse the raw string value into the right Python type:
  - boolean
  - list
  - float / int
  - string
  """

  # trim quotes
  trimmed = raw_str.strip()

  # dealing with booleans
  if trimmed.lower() == 'true':
    return True
  elif trimmed.lower() == 'false':
    return False
  # dealing with list-like objects
  if trimmed.startswith('[') and trimmed.endswith(']'):
    try:
      return literal_eval(trimmed)
    except: pass # default to a string otherwise

  # removed enclosed quotes in entries
  if (trimmed.startswith('"') and trimmed.endswith('"')) or (trimmed.startswith("'") and trimmed.endswith("'")):
    return trimmed[1:-1]

  # dealing with numerics
  time_pattern = r'^\d{2}:\d{2}:\d{2}$'
  if re.match(time_pattern, trimmed):
      return trimmed  # "00:00:01" stays as "00:00:01"

  numeric_pattern = r'^-?\d+(\.\d+)?$'
  if re.match(numeric_pattern, trimmed):
   if '.' in trimmed:
    return float(trimmed)
  else:
    return int(trimmed)

  # otherwise return the string
  return trimmed


def write_to_csv(data_list, csv_path):
  """
  Write a list of dictionaries to a CSV file. Each dict key becomes a column.
  """
  all_keys = set()
  for row in data_list:
    all_keys.update(row.keys())

  fieldnames = sorted(all_keys)

  with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:
    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(data_list)

def parse_phhs_file(phhs_file_path, csv_output_path):
  # list to store all parsed hands in the file (each hand is a dictionary)
  all_hands = []
  current_hand_data = {}
  current_hand_index = None

  with open(phhs_file_path, 'r', encoding='utf-8') as phhs_file:
    for line in phhs_file:
      line = line.strip()
      # 1. identify a new hand block which starts with "[x]"
      if re.match(r'^\[\d+\]$', line):
        # firstly, if there exists data from the previous hand, we store it before overwriting
        if current_hand_data:
          all_hands.append(current_hand_data)

        # we re-initialise the dictionary
        current_hand_data = {}

        hand_index = int(line.strip('[]'))
        current_hand_data['Hand Index'] = hand_index

      # 2. parse each line, converting to key value pairs
      elif '=' in line:
        var_name, var_value_raw = line.split('=', 1)
        var_name = var_name.strip()
        var_value_raw = var_value_raw.strip()

        # removing trailing semicolons if any
        var_value_raw = var_value_raw.rstrip(';')

        # parse and place in dictionary
        value = parse_value(var_value_raw)
        current_hand_data[var_name] = value

    # last hand in the file
    if current_hand_data:
      # Ensure "winnings" always has a value
      if "winnings" not in current_hand_data:
          current_hand_data["winnings"] = "NA"
      all_hands.append(current_hand_data)

  write_to_csv(all_hands, csv_output_path)
  print(f"CSV file '{csv_output_path}' created successfully.")

from google.colab import drive
drive.mount('/content/drive')

"""
Here, we mount the drive containing the PHHS files and we convert the
files in our folder of choice into CSV files
"""
phhs_file_paths = []
csv_output_paths = []
PHHS_file_path = ""
CSV_file_path = ""
num_files = 382

# for i in range(0, num_files):
#   csv_output_paths.append(f"{CSV_file_path}{i+1}.csv")
#   phhs_file_paths.append(f'{PHHS_file_path}{i+1}-OBFUSCATED.phhs')

# parsing the phhs files as csvs

for i in range(0, num_files):
  csv_output_paths.append(f"/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Data/CSV_cleaned/Updated_consolidated/1000NL_FTP/ps_NLH_1000_{i+1}.csv")
  phhs_file_paths.append(f'/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Data/data/handhq/FTP-2009-07-01_2009-07-23_1000NLH_OBFU/10/ftp NLH handhq_{i+1}-OBFUSCATED.phhs')
for i in range(0, num_files):
  parse_phhs_file(phhs_file_paths[i], csv_output_paths[i])

"""
Below, we do some quick data cleaning. The main things I want to achieve are to
sort each file by table name and in chronological order. Secondly, I want to
delete any hands that contain NaN or "NA" values. I think this is a reasonable
way to structure my data because it closely simulates how poker is played
(one table at a time in chronological order) and it allows me to further isolate
specific player behavior later in the project
"""

import os
import pandas as pd
import glob

csv_folder = "/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Data/CSV_cleaned/Updated_consolidated/1000NL_FTP"

# Glob for all CSVs that live in the folder

csv_files = glob.glob(os.path.join(csv_folder, "*.csv"))

# Iterate through each CSV file
for csv_file in csv_files:
  print(f"Processing {csv_file}")
  df = pd.read_csv(csv_file)

  # replace string "NA" values with an actual NaN so that dropna works
  df.replace("NA", float("nan"), inplace=True)

  # drop rows with NaN values in any column
  df.dropna(axis=0, how="any", inplace=True)

  # sorting by table and time
  df.sort_values(["table", "time"], inplace=True)

  df.to_csv(csv_file, index=False)
  print(f"Cleaned up {csv_file}")

# Combining individual CSV files into a master CSV sorted by table and time

csv_folder = "/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Data/CSV_cleaned/Updated_consolidated/1000NL_FTP"
master_csv_path = "/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Data/CSV_cleaned/Updated_consolidated/1000NL_FTP/master_1000NL.csv"

csv_files = glob.glob(os.path.join(csv_folder, "*.csv"))
list_of_dfs = []

for csv_file in csv_files:
  print(f"Reading {csv_file}")
  df = pd.read_csv(csv_file)
  list_of_dfs.append(df)

master_df = pd.concat(list_of_dfs, ignore_index=True)
master_df.sort_values(["table","time"], inplace=True)

master_df.to_csv(master_csv_path, index=False)
print(f"Master file saved at {master_csv_path}")

"""
The next order of business is to extract features from the dataset, but to do
that efficiently, we have to structure the data in a better way. We first gain
a better understanding of the dataset then use this information to build a
constructive intermetiate stage dataset
"""

import numpy as np
import pandas as pd
from ast import literal_eval
from google.colab import drive

master_file_path = "/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Data/CSV_cleaned/Updated_consolidated/1000NL_FTP/master_1000NL.csv"
master = pd.read_csv(master_file_path)

num_tables = master["table"].nunique()
print("Number of distinct tables:", num_tables)

from ast import literal_eval

master["players"] = master["players"].apply(literal_eval)
all_players = set()
for player_list in master["players"]:
  for player in player_list:
    all_players.add(player)

print("Number of distinct players:", len(all_players))

def enumerated_players(player_list):
  return list(enumerate(player_list))

master["player_enumerated"] = master["players"].apply(enumerated_players)

master

master = master[master['players'].apply(len) > 2]
master

master_exploded = master.explode("player_enumerated", ignore_index=True)
master_exploded["player_index"] = master_exploded["player_enumerated"].apply(lambda x: x[0])
master_exploded["player"] = master_exploded["player_enumerated"].apply(lambda x: x[1])
master_exploded.drop(columns=["player_enumerated"], inplace=True)

"""
We have previously defined a sequence to be a group of N consecutive hands
played by a single player. The rationale behind involving sequences is that tilt
is usually not an isolated phenomenon; rather, it emerges as a response to
patterns of outcomes a player experiences over a series of hands. To capture
the temporal dependence of poker behavior, sequences were constructed using a
sliding window approach with an overlap of hands. For each sequence, tilt
relevant metrics were extracted to represent cumulative behavior within the
sequence and these sequences form the basis for both unsupervised label
assignment and supervised prediction.

The first step to achieving this is to isolate the hands played by each player
in chronological order on a table by table basis
"""


# master_exploded.rename(columns={"players": "player"}, inplace=True)
master_exploded.sort_values(by=["player", "table", "time"], inplace=True)

# # we are interested in how many hands a player played on a given table

# we pick 50 as the threshold, so that we ignore players that played less than 50 hands on a table
k = 50
grouped = master_exploded.groupby(["player", "table"]).size().reset_index(name="num_hands")
filtered = grouped[grouped["num_hands"] >= k]

master_exploded["player_table_count"] = master_exploded.groupby(["player", "table"])["Hand Index"].transform("count")

master_exploded_filtered = master_exploded[master_exploded["player_table_count"] >= k].copy()
master_exploded_filtered.drop(columns=["player_table_count"], inplace=True)

master_exploded_filtered

master_exploded_filtered.to_csv("/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Code/Redone/FTP_Output/1000NL_master_exploded_filtered")

string_cols = ['starting_stacks','actions']
for col in string_cols:
  master_exploded_filtered[col] = master_exploded_filtered[col].apply(literal_eval)

def build_sequences(df, seq_len=8, step=4):
  final_dict = {}
  grouped = df.groupby(['player','table'],group_keys=True)

  for (player, table), group_df in grouped:
    rows_list = group_df[["Hand Index", "starting_stacks", "player_index", "actions"]].to_dict(orient="records")

    # we will then slice
    windows_for_this_player_table = []
    i = 0
    while i + seq_len <= len(rows_list):
      window = rows_list[i:i+seq_len]
      detailed_window = []
      for row in window:
        p_idx = row["player_index"]
        stack_list = row["starting_stacks"]
        player_stack = stack_list[p_idx]
        actions = row["actions"]
        player_label = f"p{p_idx + 1}"
        detailed_window.append((player_stack, actions, player_label))
      windows_for_this_player_table.append(detailed_window)
      i += step

    final_dict[(player,table)] = windows_for_this_player_table
  return final_dict

# we end up with floor((N-sequence_length)/slide) + 1 sequences where N is the number of hands

data = master_exploded_filtered
seq_len = 8
step = 4
sequencesDictionary = build_sequences(data, seq_len, step)

# We now move on to extracting metrics we deem relevant for assessing tilt

import re
import numpy as np
import pandas as pd
from collections import defaultdict
from scipy.stats import linregress

def parse_player_action(actions, player_token):
  """
  this will return a list of actions taken by hero
  given an input actions list
  """
  player_actions = [act for act in actions if act.startswith(player_token)]
  return player_actions

def extract_bet_amount(action_str):
  """
  given an action string, extract the bet amount if present. We
  then return the bet amount or 0.
  """
  match = re.search(r'(cbr|cc)\s+(\d+(\.\d+)?)', action_str)
  if match:
    return float(match.group(2))
  else:
    return 0.0

def is_aggressive_action(action_str):
  # we define an aggressive action as cbr
  return 'cbr' in action_str

actions = [  'd dh p1 ????',  'd dh p2 ????',  'p2 cbr 30',     'p1 cc',  'd db 9d3d5h',
  'p1 cc',  'p2 cbr 48',     'p1 cc',  'd db 2c',       'p1 cc',  'p2 cc',
      'd db 7s',  'p1 cbr 110',    'p2 cc',  'p1 sm 9cQd',    'p2 sm ????']
act_str = 'p2 cbr 30'
extract_bet_amount(act_str)
is_aggressive_action(act_str)

def compute_hand_metrics(hand, previous_starting_stack=None):
  """
  For one hand (tuple: (starting_stack, actions, player_index)),
  parse the player's actions and compute:
    - total bet amount (sum of amounts from aggressive actions)
    - number of aggressive actions (count of actions with 'cbr')
    - total number of actions for that player
    - outcome indicator (1 for win, -1 for loss, 0 for neutral) if prev_starting_stack provided;
      outcome is determined by comparing current starting_stack with prev_starting_stack.
    - loss_fraction: if loss, (prev_starting_stack - current_starting_stack) / prev_starting_stack.
  Returns a dictionary.
  """
  starting_stack, actions, player_index = hand
  player_actions = parse_player_action(actions, player_index)
  total_bet = 0.0
  aggressive_count = 0
  for act in player_actions:
    if is_aggressive_action(act):
      amt = extract_bet_amount(act)
      total_bet += amt
      aggressive_count += 1
  total_actions = len(player_actions) if player_actions else 1
  aggression_fraction = aggressive_count / total_actions

  outcome = None
  loss_fraction = 0.0
  if previous_starting_stack is not None:
    if starting_stack < previous_starting_stack:
      outcome = -1 # a loss
      loss_fraction = (previous_starting_stack - starting_stack) / previous_starting_stack
    elif starting_stack > previous_starting_stack:
      outcome = 1 # a win
    else:
      outcome = 0 # neutral

  risk_fraction = total_bet / starting_stack if starting_stack > 0 else 0.0
  return {
      'starting_stack': starting_stack,
      'total_bet': total_bet,
      'risk_fraction': risk_fraction,
      'aggressive_count': aggressive_count,
      'total_actions': total_actions,
      'aggression_fraction': aggression_fraction,
      'outcome': outcome,
      'loss_fraction': loss_fraction
  }

def process_sequence(sequence):
  """
    Given a sequence (list of hand tuples), compute sequence-level metrics:
      - Maximum consecutive losses
      - Weighted loss impact (sum of loss fractions)
      - Significant loss count (loss > 50% of previous stack)
      - Risk metrics: list of risk fractions → average, variance, maximum
      - Aggression metrics: list of aggression fractions; also dynamic change (first vs second half),
        post-loss aggression (average aggression in hands following a loss), and trend slope.
    Returns a dictionary with computed metrics and lists for baseline aggregation.
    """
  hand_metrics = []
  prev_stack = None
  outcomes = []
  risk_list = []
  agg_list = []
  post_loss_aggs = []

  for i, hand in enumerate(sequence):
    metrics = compute_hand_metrics(hand, previous_starting_stack=prev_stack)
    hand_metrics.append(metrics)
    if i > 0:
      outcomes.append(metrics['outcome'])
      if hand_metrics[i-1]['outcome'] == -1:
        post_loss_aggs.append(metrics['aggression_fraction'])
    risk_list.append(metrics['risk_fraction'])
    agg_list.append(metrics['aggression_fraction'])
    prev_stack = metrics['starting_stack']

  # we also want the maximum consecutive losses
  max_consec_losses = 0
  current_streak = 0
  weighted_loss_impact = 0.0
  significant_loss_count = 0
  for outcome, hand in zip(outcomes, hand_metrics[1:]):
    if outcome == -1:
      current_streak += 1
      weighted_loss_impact += hand['loss_fraction']
      if hand['loss_fraction'] > 0.5:
        significant_loss_count += 1
    else:
      max_consec_losses = max(max_consec_losses, current_streak)
      current_streak = 0
  max_consec_losses = max(max_consec_losses, current_streak)

  # risk metrics
  avg_risk = np.mean(risk_list) if risk_list else 0.0
  risk_variance = np.var(risk_list) if risk_list else 0.0
  max_risk = max(risk_list) if risk_list else 0.0

  # aggression metrics
  avg_aggression = np.mean(agg_list) if agg_list else 0.0
  mid = len(agg_list) // 2 # we split the sequence into 2 halves for dynamic aggression change
  if mid > 0:
    early_avg = np.mean(agg_list[:mid])
    late_avg = np.mean(agg_list[mid:])
    dynamic_agg_change = early_avg - late_avg
  else:
    dynamic_agg_change = 0.0
  post_loss_aggression_ratio = np.mean(post_loss_aggs) if post_loss_aggs else np.nan
  # now, over the course of the sequence
  if len(agg_list) > 1:
    x = np.arange(len(agg_list))
    slope, intercept, r_value, p_value, std_err = linregress(x, agg_list)
  else:
    slope = 0.0

  sequence_metrics = {
      'max_consecutive_losses': max_consec_losses,
      'weighted_loss_impact': weighted_loss_impact,
      'significant_loss_count': significant_loss_count,
      'avg_risk': avg_risk,
      'risk_variance': risk_variance,
      'max_risk': max_risk,
      'avg_aggression': avg_aggression,
      'dynamic_aggression_change': dynamic_agg_change,
      'post_loss_aggression_ratio': post_loss_aggression_ratio,
      'aggression_trend_slope': slope,
      # For baseline aggregation later
      'risk_list': risk_list,
      'aggression_list': agg_list
  }
  return sequence_metrics

# in the first pass, we process every sequence and collect per-player baselines
# we then store sequence-level results in a list

results = []

# we store per player values
player_risk_baseline = defaultdict(list)
player_agg_baseline = defaultdict(list)
player_MCL_baseline = defaultdict(list)
player_WLI_baseline = defaultdict(list)

for (player_id, table_id), sequences in sequencesDictionary.items():
  for seq_index, sequence in enumerate(sequences):
    seq_metrics = process_sequence(sequence)
    # append baseline risk and aggression values for this player
    player_risk_baseline[player_id].extend(seq_metrics['risk_list'])
    player_agg_baseline[player_id].append(seq_metrics['avg_aggression'])
    player_MCL_baseline[player_id].append(seq_metrics['max_consecutive_losses'])
    player_WLI_baseline[player_id].append(seq_metrics['weighted_loss_impact'])

    # results entry with some metadata
    result = {
        'PlayerID': player_id,
        'TableID': table_id,
        'SequenceIndex': seq_index,
        'MaxConsecutiveLosses': seq_metrics['max_consecutive_losses'],
        'WeightedLossImpact': seq_metrics['weighted_loss_impact'],
        'SignificantLossCount': seq_metrics['significant_loss_count'],
        'AverageRisk': seq_metrics['avg_risk'],
        'RiskVariance': seq_metrics['risk_variance'],
        'MaxRisk': seq_metrics['max_risk'],
        'AverageAggression': seq_metrics['avg_aggression'],
        'DynamicAggressionChange': seq_metrics['dynamic_aggression_change'],
        'PostLossAggressionRatio': seq_metrics['post_loss_aggression_ratio'],
        'AggressionTrendSlope': seq_metrics['aggression_trend_slope']
    }
    results.append(result)

player_baselines = {}
for player_id in player_risk_baseline:
  # risk and aggression baselines
  risk_values = np.array(player_risk_baseline[player_id])
  agg_values = np.array(player_agg_baseline[player_id])
  risk_mean = np.mean(risk_values) if len(risk_values) > 0 else 0.0
  risk_std = np.std(risk_values) if len(risk_values) > 0 else 1.0
  agg_mean = np.mean(agg_values) if len(agg_values) > 0 else 0.0
  agg_std = np.std(agg_values) if len(agg_values) > 0 else 1.0

  # MCL and WLI baselines
  MCL_values = np.array(player_risk_baseline[player_id])
  WLI_values = np.array(player_agg_baseline[player_id])
  MCL_mean = np.mean(MCL_values) if len(MCL_values) > 0 else 0.0
  MCL_std = np.std(MCL_values) if len(MCL_values) > 0 else 1.0
  WLI_mean = np.mean(WLI_values) if len(WLI_values) > 0 else 0.0
  WLI_std = np.std(WLI_values) if len(WLI_values) > 0 else 1.0
  player_baselines[player_id] = {
      'risk_mean': risk_mean,
      'risk_std': risk_std,
      'agg_mean': agg_mean,
      'agg_std': agg_std,
      'MCL_mean': MCL_mean,
      'MCL_std': MCL_std,
      'WLI_mean': WLI_mean,
      'WLI_std': WLI_std
  }

# Creating a DataFrame from the 'results' list
df = pd.DataFrame(results)  # This line creates the DataFrame

for entry in results:
  player_id = entry['PlayerID']
  baseline = player_baselines.get(player_id, {'risk_mean':0, 'risk_std': 1, 'agg_mean': 0, 'agg_std': 1})
  # z score for risk
  entry['RiskZ'] = (entry['AverageRisk'] - baseline['risk_mean']) / (baseline['risk_std'] if baseline['risk_std'] != 0 else 1)
  # z score for aggression
  entry['AggressionZ'] = (entry['AverageAggression'] - baseline['agg_mean']) / (baseline['agg_std'] if baseline['agg_std'] != 0 else 1)

# Set weights (to tune later)
w1 = 0.05  # weight for max consecutive losses (MCL)
w2 = 0.15 # weight for weighted loss impact (WLI)
w3 = 0.6  # weight for average risk
w4 = 0.1 # weight for average aggression
w5 = 0.1  # weight for dynamic aggression change

# We'll compute additional columns in the dataframe:
def compute_cti(row):
    player = row['PlayerID'] # Accessing the 'PlayerID' column
    baseline = player_baselines.get(player, {'MCL_mean':0, 'MCL_std':1, 'WLI_mean':0, 'WLI_std':1,
                                               'risk_mean':0, 'risk_std':1, 'agg_mean':0, 'agg_std':1})
    # Compute z-scores for MCL, WLI, risk, aggression
    Z_MCL = (row['MaxConsecutiveLosses'] - baseline['MCL_mean']) / baseline['MCL_std']
    Z_WLI = (row['WeightedLossImpact'] - baseline['WLI_mean']) / baseline['WLI_std']
    Z_Risk = (row['AverageRisk'] - baseline['risk_mean']) / baseline['risk_std']
    Z_Agg  = (row['AverageAggression'] - baseline['agg_mean']) / baseline['agg_std']

    # Delta_A is the raw dynamic aggression change (you could also normalize this if desired)
    Delta_A = row['DynamicAggressionChange']

    # Composite Tilt Indicator (CTI)
    CTI = w1 * Z_MCL + w2 * Z_WLI + w3 * Z_Risk + w4 * Z_Agg + w5 * Delta_A
    return CTI

df['CompositeTiltIndicator'] = df.apply(compute_cti, axis=1) # Applying the function to the DataFrame
df['NormalizedCTI'] = 1 / (1+np.exp(-df['CompositeTiltIndicator']))
df['Tilt_label'] = df['NormalizedCTI'].apply(lambda x: 1 if x >= 0.95 else 0)

csv_filename = "/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Code/Redone/tilt_metrics_labeled_FTP.csv"
df.to_csv(csv_filename, index=False)
print(f"CSV file '{csv_filename}' has been written with composite tilt indicator for {len(df)} sequences.")

# prompt:  plot the NormalizedCTI histogram

import matplotlib.pyplot as plt

# Assuming 'df' is your DataFrame with the 'NormalizedCTI' column
plt.hist(df['NormalizedCTI'], bins=30)  # Adjust bins as needed
plt.xlabel('Normalized CTI')
plt.ylabel('Frequency')
plt.title('Histogram of Normalized CTI')
plt.show()

# prompt: plot the distribution of weighted loss impact

import matplotlib.pyplot as plt

# Assuming 'df' is your DataFrame with the 'NormalizedCTI' column
plt.hist(df['MaxRisk'], bins=30)  # Adjust bins as needed
plt.xlabel('MaxRisk')
plt.ylabel('Frequency')
plt.title('Distribution of MaxRisk')
plt.show()

import pandas as pd
import numpy as np
from scipy.stats import mannwhitneyu
import matplotlib.pyplot as plt

# Label sequences as tilted if their NormalizedCompositeTiltIndicator is in the top 5%
threshold = df['NormalizedCTI'].quantile(0.95)

print(f"Threshold for tilt labeling (top 5%): {threshold:.3f}")
print(f"Number of sequences labeled as tilt: {df['Tilt_label'].sum()} out of {len(df)}")

# Assume that 'MaxRisk' is your performance metric (exponentially distributed)
tilt_group = df[df['Tilt_label'] == 1]['MaxRisk']
non_tilt_group = df[df['Tilt_label'] == 0]['MaxRisk']

# Since MaxRisk appears exponentially distributed, use the Mann-Whitney U test
u_stat, p_value = mannwhitneyu(tilt_group, non_tilt_group, alternative='two-sided')
print("\nMann-Whitney U test results:")
print(f"U-statistic: {u_stat}")
print(f"p-value: {p_value:.3e}")

# Visualize the distribution of MaxRisk for both groups
plt.figure(figsize=(10, 6))
plt.hist(tilt_group, bins=50, alpha=0.6, label="Tilt Group (Top 5%)", color='red')
plt.hist(non_tilt_group, bins=50, alpha=0.6, label="Non-Tilt Group (Bottom 95%)", color='blue')
plt.xlabel("MaxRisk")
plt.ylabel("Frequency")
plt.title("Distribution of MaxRisk for Tilt and Non-Tilt Sequences")
plt.legend()
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.utils import class_weight

# Load your dataset that includes the engineered features and the TiltLabel
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Senior Thesis/Code/Redone/tilt_metrics_labeled_FTP.csv")

# Define the feature columns that we will use for prediction.
# (Adjust this list based on your actual feature names.)
feature_cols = [
    'MaxConsecutiveLosses',
    'WeightedLossImpact',
    'SignificantLossCount',
    'AverageRisk',
    'RiskVariance',
    'MaxRisk',
    'AverageAggression',
    'DynamicAggressionChange',
    'AggressionTrendSlope',
    'RiskZ',
    'AggressionZ'
]

# Extract features (X) and target (y)
X = df[feature_cols].values
y = df['Tilt_label'].values

# Because only ~5% of sequences are tilted, compute class weights
classes = np.unique(y)
weights = class_weight.compute_class_weight('balanced', classes=classes, y=y)
class_weights = {i: weight for i, weight in zip(classes, weights)}
print("Class weights:", class_weights)

# Split the dataset into training and testing sets (e.g., 80/20 split)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Build a simple feedforward neural network
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification

# Compile the model with Adam optimizer and binary cross-entropy loss
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# Use early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=100,
    batch_size=256,
    class_weight=class_weights,
    callbacks=[early_stopping]
)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test loss: {loss:.3f}, Test accuracy: {accuracy:.3f}")

# Predict tilt labels on the test set
y_pred_prob = model.predict(X_test).ravel()
y_pred = (y_pred_prob >= 0.5).astype(int)

print("Classification Report:")
print(classification_report(y_test, y_pred))
print("ROC AUC:", roc_auc_score(y_test, y_pred_prob))

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, precision_recall_curve

# ----- Plot Training History -----
plt.figure(figsize=(12, 5))

# Plot Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Training and Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

# Plot Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title("Training and Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.tight_layout()
plt.show()

# ----- Confusion Matrix -----
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Non-Tilt", "Tilt"])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# ----- ROC Curve -----
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], "k--")  # Diagonal line for reference
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operating Characteristic (ROC) Curve")
plt.legend(loc="lower right")
plt.show()

# ----- Precision-Recall Curve (Optional) -----
precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)
plt.figure(figsize=(8, 6))
plt.plot(recall, precision, label="Precision-Recall Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="upper right")
plt.show()